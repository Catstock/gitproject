{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件列表：\n",
      "1: 00473.mp4\n",
      "2: 1.mp4\n",
      "3: 741400163.mp4\n",
      "4: 731200067.mp4\n",
      "5: 517600078\n",
      "6: 1\n",
      "7: 796100172.mp4\n",
      "8: 620900105.mp4\n",
      "你选择的文件是：00473.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./misc/Pose_Source/00473.mp4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以使用Python中的os和os.path模块来实现列出文件夹下的所有文件，并使用input函数获取用户输入的文件名。\n",
    "\n",
    "#下面是一个简单的实现例子：\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def folder_file_path_confirm(folder_name):\n",
    "    \n",
    "    # 获取文件夹路径\n",
    "    folder_path = './misc'+folder_name\n",
    "# 获取文件夹中的所有文件\n",
    "    files = os.listdir(folder_path)\n",
    "# 获取用户选择的文件\n",
    "    file_index = int(input(\"请选择一个文件：\"))\n",
    "    selected_file = files[file_index - 1]\n",
    "    print(f\"你选择的文件是：{selected_file}\")\n",
    "\n",
    "    return folder_path+'/'+selected_file\n",
    "def folder_file_path_show(folder_name):\n",
    "    # 获取文件夹路径\n",
    "    folder_path = './misc'+folder_name\n",
    "# 获取文件夹中的所有文件\n",
    "    files = os.listdir(folder_path)\n",
    "    print(\"文件列表：\")\n",
    "    for i, file_name in enumerate(files):\n",
    "        print(f\"{i + 1}: {file_name}\")\n",
    "    return \n",
    "folder_file_path_show('/Pose_Source')\n",
    "folder_file_path_confirm('/Pose_Source')\n",
    "#注意：以上代码只是一个基本的实现例子，如果要用于实际应用程序开发，还需要进行输入校验和异常处理等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件列表：\n",
      "1: 00473.mp4\n",
      "2: 1.mp4\n",
      "3: 00473\n",
      "4: 741400163.mp4\n",
      "5: 731200067.mp4\n",
      "6: 517600078\n",
      "7: 1\n",
      "8: 796100172.mp4\n",
      "9: 620900105.mp4\n",
      "你选择的文件是：00473.mp4\n",
      "文件列表：\n",
      "1: 741400104.mp4\n",
      "2: 681600002.mp3\n",
      "3: 741400104.mp3\n",
      "4: 681100216.mp4\n",
      "5: 00015.mp4\n",
      "6: 00086.mp4\n",
      "7: 00015.mp3\n",
      "8: 00373.mp4\n",
      "你选择的文件是：681600002.mp3\n",
      "文件列表：\n",
      "1: 741400163\n",
      "2: 00098.mp4\n",
      "3: 00098\n",
      "4: 749400016\n",
      "5: 517600055\n",
      "6: 512400353\n",
      "7: 00010.mp4\n",
      "8: 00002.mp4\n",
      "9: 581600416\n",
      "你选择的文件是：00098\n",
      "meta-info saved at ./misc/PatientNameaudio_contentdate.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: './misc/Audio_Source/681600002.mp3' and './misc/Audio_Source/681600002.mp3' are the same file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', './scripts/prepare_testing_files.py', '--src_pose_path', './misc/Pose_Source/00473.mp4', '--src_audio_path', './misc/Audio_Source/681600002.mp3', '--src_input_path', './misc/Input/00098', '--csv_path', './misc/PatientNameaudio_contentdate.csv'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "csv_file_name='PatientName'+'audio_content'+'date'+'.csv'\n",
    "# 要执行的Python文件的名称和参数\n",
    "python_file = './scripts/prepare_testing_files.py'\n",
    "#\n",
    "#folder_file_path_confirm('/Pose_Source')\n",
    "folder_file_path_show('/Pose_Source')\n",
    "pose_path =folder_file_path_confirm('/Pose_Source')\n",
    "folder_file_path_show('/Audio_Source')\n",
    "audio_path=folder_file_path_confirm('/Audio_Source')\n",
    "folder_file_path_show('/Input')\n",
    "input_path=folder_file_path_confirm('/Input')\n",
    "csv_path='./misc/'+csv_file_name\n",
    "# arg_pose = '--src_pose_path'+pose_path\n",
    "# arg_audio = '--src_audio_path'+' '+audio_path\n",
    "# arg_input ='--src_input_path'+' '+input_path\n",
    "# arg_csv='--csv_path'+' '+csv_path\n",
    "# 使用subprocess模块执行Python文件\n",
    "\n",
    "subprocess.run(['python', python_file,\n",
    "                '--src_pose_path', pose_path,\n",
    "                '--src_audio_path',audio_path,\n",
    "                '--src_input_path',input_path,\n",
    "                '--csv_path',csv_path\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-hm/Documents/project/hos_project/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu-hm/Documents/project/hos_project/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In models.networks.encoder, there should be a class whose name matches assertionerrorresseaudioencoder in lowercase without underscore(_)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'inference.py', '--name', 'demo', '--meta_path_vox', './misc/PatientNameaudio_contentdate.csv', '--dataset_mode', 'voxtest', '--netG', 'modulate', '--netA', 'AssertionErrorresseaudio', '--netA_sync', 'ressesync', '--netD', 'multiscale', '--netV', 'resnext', '--netE', 'fan', '--model', 'av', '--gpu_ids', '0', '--clip_len', '1', '--batchSize', '16', '--style_dim', '2560 ', '--nThreads', '4 ', '--input_id_feature', '--generate_interval', '1', '--style_feature_loss', '--use_audio 1', '--noise_pose', '--driving_pose', '--gen_video', '--generate_from_audio_only'], returncode=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['python','inference.py',  \n",
    "                '--name', 'demo',\n",
    "                '--meta_path_vox',csv_path,\n",
    "        '--dataset_mode', 'voxtest' ,\n",
    "        '--netG','modulate',\n",
    "        '--netA', 'AssertionErrorresseaudio',\n",
    "        '--netA_sync', 'ressesync',\n",
    "        '--netD', 'multiscale',\n",
    "        '--netV', 'resnext',\n",
    "        '--netE' ,'fan',\n",
    "        '--model' ,'av',\n",
    "        '--gpu_ids' ,'0',\n",
    "        '--clip_len' ,'1' ,\n",
    "        '--batchSize', '16' ,\n",
    "        '--style_dim', '2560 ',\n",
    "        '--nThreads' ,'4 ',\n",
    "        '--input_id_feature',\n",
    "        '--generate_interval', '1' ,\n",
    "        '--style_feature_loss',\n",
    "        '--use_audio 1',\n",
    "        '--noise_pose',\n",
    "        '--driving_pose',\n",
    "        '--gen_video',\n",
    "        '--generate_from_audio_only'\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修改shell文件首行来更改csv文件名，更改执行的csv，以达到更改音频，图片，视频生成的效果\n",
    "def sh_file_edit(name):\n",
    "    # 打开.sh文件并读取所有行\n",
    "    sh_file_path='./experiments/demo_vox.sh'\n",
    "    with open(sh_file_path, 'r') as file:\n",
    "        filedata = file.readlines()\n",
    "\n",
    "# 在特定行替换文本\n",
    "    \n",
    "#meta_path_vox='./misc/demo.csv'\n",
    "    csv_file_name=name\n",
    "    new_text = 'meta_path_vox='+'\\'./misc/'+csv_file_name+'\\''+'\\n'\n",
    "\n",
    "    filedata[0] = new_text \n",
    "# 将修改后的文本写回到文件中\n",
    "    with open(sh_file_path, 'w') as file:\n",
    "        file.writelines(filedata)\n",
    "sh_file_edit(csv_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-hm/Documents/project/hos_project/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu-hm/Documents/project/hos_project/venv/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "usage: inference.py [-h] [--name NAME] [--filename_tmpl FILENAME_TMPL]\n",
      "                    [--data_path DATA_PATH] [--lrw_data_path LRW_DATA_PATH]\n",
      "                    [--gpu_ids GPU_IDS] [--num_classes NUM_CLASSES]\n",
      "                    [--checkpoints_dir CHECKPOINTS_DIR] [--model MODEL]\n",
      "                    [--trainer TRAINER] [--norm_G NORM_G] [--norm_D NORM_D]\n",
      "                    [--norm_E NORM_E] [--norm_A NORM_A] [--phase PHASE]\n",
      "                    [--batchSize BATCHSIZE]\n",
      "                    [--preprocess_mode {resize_and_crop,crop,scale_width,scale_width_and_crop,scale_shortside,scale_shortside_and_crop,fixed,none}]\n",
      "                    [--crop_size CROP_SIZE] [--crop_len CROP_LEN]\n",
      "                    [--target_crop_len TARGET_CROP_LEN] [--crop]\n",
      "                    [--clip_len CLIP_LEN] [--pose_dim POSE_DIM]\n",
      "                    [--frame_interval FRAME_INTERVAL] [--num_clips NUM_CLIPS]\n",
      "                    [--num_inputs NUM_INPUTS]\n",
      "                    [--feature_encoded_dim FEATURE_ENCODED_DIM]\n",
      "                    [--aspect_ratio ASPECT_RATIO] [--output_nc OUTPUT_NC]\n",
      "                    [--audio_nc AUDIO_NC] [--frame_rate FRAME_RATE]\n",
      "                    [--num_frames_per_clip NUM_FRAMES_PER_CLIP]\n",
      "                    [--hop_size HOP_SIZE]\n",
      "                    [--generate_interval GENERATE_INTERVAL] [--dis_feat_rec]\n",
      "                    [--train_recognition] [--train_sync] [--train_word]\n",
      "                    [--train_dis_pose] [--generate_from_audio_only]\n",
      "                    [--noise_pose] [--style_feature_loss]\n",
      "                    [--dataset_mode DATASET_MODE] [--landmark_align]\n",
      "                    [--serial_batches] [--no_flip] [--nThreads NTHREADS]\n",
      "                    [--n_mel_T N_MEL_T]\n",
      "                    [--num_bins_per_frame NUM_BINS_PER_FRAME]\n",
      "                    [--max_dataset_size MAX_DATASET_SIZE]\n",
      "                    [--load_from_opt_file] [--use_audio USE_AUDIO]\n",
      "                    [--use_audio_id USE_AUDIO_ID] [--augment_target]\n",
      "                    [--verbose] [--display_winsize DISPLAY_WINSIZE]\n",
      "                    [--netG NETG] [--netA NETA] [--netA_sync NETA_SYNC]\n",
      "                    [--netV NETV] [--netE NETE] [--netD NETD]\n",
      "                    [--D_input D_INPUT] [--driven_type DRIVEN_TYPE]\n",
      "                    [--landmark_type LANDMARK_TYPE] [--ngf NGF]\n",
      "                    [--init_type INIT_TYPE] [--feature_fusion FEATURE_FUSION]\n",
      "                    [--init_variance INIT_VARIANCE] [--no_instance]\n",
      "                    [--input_id_feature] [--load_landmark] [--nef NEF]\n",
      "                    [--style_dim STYLE_DIM] [--vgg_face]\n",
      "                    [--VGGFace_pretrain_path VGGFACE_PRETRAIN_PATH]\n",
      "                    [--lambda_feat LAMBDA_FEAT] [--lambda_image LAMBDA_IMAGE]\n",
      "                    [--lambda_vgg LAMBDA_VGG]\n",
      "                    [--lambda_vggface LAMBDA_VGGFACE]\n",
      "                    [--lambda_rotate_D LAMBDA_ROTATE_D] [--lambda_D LAMBDA_D]\n",
      "                    [--lambda_softmax LAMBDA_SOFTMAX]\n",
      "                    [--lambda_crossmodal LAMBDA_CROSSMODAL]\n",
      "                    [--lambda_contrastive LAMBDA_CONTRASTIVE] [--ndf NDF]\n",
      "                    [--no_ganFeat_loss] [--no_vgg_loss] [--no_id_loss]\n",
      "                    [--word_loss] [--no_spectrogram] [--gan_mode GAN_MODE]\n",
      "                    [--no_TTUR] [--optimizer OPTIMIZER] [--beta1 BETA1]\n",
      "                    [--beta2 BETA2] [--lr LR] [--no_gaussian_landmark]\n",
      "                    [--label_mask] [--positional_encode] [--use_transformer]\n",
      "                    [--has_mask] [--heatmap_size HEATMAP_SIZE]\n",
      "                    [--results_dir RESULTS_DIR] [--input_path INPUT_PATH]\n",
      "                    [--meta_path_vox META_PATH_VOX] [--driving_pose]\n",
      "                    [--list_num LIST_NUM]\n",
      "                    [--fitting_iterations FITTING_ITERATIONS]\n",
      "                    [--which_epoch WHICH_EPOCH] [--how_many HOW_MANY]\n",
      "                    [--start_ind START_IND] [--list_start LIST_START]\n",
      "                    [--list_end LIST_END] [--save_path SAVE_PATH]\n",
      "                    [--multi_gpu] [--defined_driven] [--gen_video] [--onnx]\n",
      "                    [--mode MODE] [--no_pairing_check]\n",
      "inference.py: error: unrecognized arguments: \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#执行shell\n",
    "import os\n",
    "os.system('./experiments/demo_vox.sh') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
